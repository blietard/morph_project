{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "208ca30c-4e35-4cd2-90ed-695d61e167a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9a11048-4f0c-4dda-846e-24265a7f50ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assembler:\n",
    "    \n",
    "    def __init__(self, grouped_stems: List, ngrams_per_attr_group: List):\n",
    "        self.grouped_stems = grouped_stems\n",
    "        self.ngrams_per_attr_group = ngrams_per_attr_group\n",
    "        self.assemblers = {}\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Parsing each group of lemmas\n",
    "        for i_lemma_group, lemma_group in enumerate(grouped_stems):\n",
    "            # Parsing each entry\n",
    "            for stem, final, i_morph_attr_group in lemma_group:\n",
    "                \n",
    "                # Computing matching array\n",
    "                # TODO: only handling exact matching at this point\n",
    "                matching_array = -2 * np.ones(len(final))\n",
    "                \n",
    "                ngrams = self.ngrams_per_attr_group[i_morph_attr_group]\n",
    "                \n",
    "                # Finding stem and updating matching array\n",
    "                i_stem = final.find(stem)\n",
    "                if i_stem != -1:\n",
    "                    matching_array[i_stem:i_stem+len(stem)] = -1\n",
    "                \n",
    "                # Trying to match every ngram of the list into the matching array\n",
    "                for i, ngram in enumerate(ngrams):\n",
    "                    print(ngram)\n",
    "                    res = 0\n",
    "                    while True:\n",
    "                        res = final.find(ngram, res)\n",
    "                        print(res)\n",
    "                        if res == -1:\n",
    "                            break\n",
    "                        if matching_array[res] == -2:\n",
    "                            matching_array[res:res+len(ngram)] = i\n",
    "                            break\n",
    "                        else:\n",
    "                            res += len(ngram)\n",
    "                            if res >= len(final):\n",
    "                                res = -1\n",
    "                \n",
    "                # TODO: if there are non-matched characters, we ignore them for the moment\n",
    "                # We could maybe \"augment\" the ngrams, adding them at the end of the list ?\n",
    "                matching_array = np.delete(matching_array, np.where(matching_array == -2))\n",
    "                \n",
    "                # Reducing the array into an ordering\n",
    "                _, idx = np.unique(matching_array, return_index=True)\n",
    "                ordering = matching_array[np.sort(idx)]\n",
    "                \n",
    "                # Adding the ordering to the list of results \n",
    "                # for its lemma group and morphological attributes group\n",
    "                if (i_group,i_morph_attr_group) in results:\n",
    "                    results[(i_group,i_morph_attr_group)].append(ordering)\n",
    "                else:\n",
    "                    results[(i_group,i_morph_attr_group)] = [ordering]\n",
    "                    \n",
    "        # For each combination, determining the most common ordering\n",
    "        for key in results:\n",
    "            \n",
    "            orderings_list = results[key]\n",
    "            \n",
    "            # TODO: in case of equality, the first ordering in the list wins\n",
    "            max_freq = 0\n",
    "            most_common = orderings_list[0]\n",
    "            for ordering in orderings_list:\n",
    "                freq = orderings_list.count(ordering)\n",
    "                if freq > max_freq:\n",
    "                    max_freq = freq\n",
    "                    most_common = ordering\n",
    "            \n",
    "            self.assemblers[key] = most_common\n",
    "            \n",
    "        \n",
    "    def pred(self, stem: str, i_lemma_group: int, i_morph_attr_group: int):\n",
    "        \n",
    "        assembler = self.assemblers[(i_lemma_group,i_morph_attr_group)]\n",
    "        possible_ngrams = self.ngrams_per_attr_group[i_morph_attr_group]\n",
    "        \n",
    "        prediction = \"\"\n",
    "        \n",
    "        for i in assembler:\n",
    "            if i == -1:\n",
    "                prediction += stem  \n",
    "            else:\n",
    "                prediction += possible_ngrams[i]\n",
    "                \n",
    "        return prediction\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0498c6f7-a38a-47aa-9d2d-64ef430b0d18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
