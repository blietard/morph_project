{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "208ca30c-4e35-4cd2-90ed-695d61e167a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e9a11048-4f0c-4dda-846e-24265a7f50ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assembler:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.grouped_stems = grouped_stems\n",
    "        self.ngrams_per_attr_group = ngrams_per_attr_group\n",
    "        self.assemblers = {}\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Parsing each group of lemmas\n",
    "        for i_lemma_group, lemma_group in enumerate(grouped_stems):\n",
    "            # Parsing each entry\n",
    "            for stem, final, i_morph_attr_group in lemma_group:\n",
    "                \n",
    "                # Computing matching array\n",
    "                # TODO: only handling exact matching at this point\n",
    "                matching_array = -2 * np.ones(len(final))\n",
    "                \n",
    "                ngrams = self.ngrams_per_attr_group[i_morph_attr_group]\n",
    "                \n",
    "                # Finding stem and updating matching array\n",
    "                i_stem = final.find(stem)\n",
    "                if i_stem != -1:\n",
    "                    matching_array[i_stem:i_stem+len(stem)] = -1\n",
    "                \n",
    "                # Trying to match every ngram of the list into the matching array\n",
    "                for i, ngram in enumerate(ngrams):\n",
    "                    #print(ngram)\n",
    "                    res = 0\n",
    "                    while True:\n",
    "                        res = final.find(ngram, res)\n",
    "                        #print(res)\n",
    "                        if res == -1:\n",
    "                            break\n",
    "                        if matching_array[res] == -2:\n",
    "                            matching_array[res:res+len(ngram)] = i\n",
    "                            break\n",
    "                        else:\n",
    "                            res += len(ngram)\n",
    "                            if res >= len(final):\n",
    "                                res = -1\n",
    "                \n",
    "                # TODO: if there are non-matched characters, we ignore them for the moment\n",
    "                # We could maybe \"augment\" the ngrams, adding them at the end of the list ?\n",
    "                matching_array = np.delete(matching_array, np.where(matching_array == -2))\n",
    "                \n",
    "                # Reducing the array into an ordering\n",
    "                _, idx = np.unique(matching_array, return_index=True)\n",
    "                ordering = list(matching_array[np.sort(idx)].astype(int))\n",
    "                \n",
    "                # Adding the ordering to the list of results \n",
    "                # for its lemma group and morphological attributes group\n",
    "                if (i_lemma_group,i_morph_attr_group) in results:\n",
    "                    results[(i_lemma_group,i_morph_attr_group)].append(ordering)\n",
    "                else:\n",
    "                    results[(i_lemma_group,i_morph_attr_group)] = [ordering]\n",
    "                    \n",
    "        # For each combination, determining the most common ordering\n",
    "        for key in results:\n",
    "            \n",
    "            orderings_list = results[key]\n",
    "            \n",
    "            # TODO: in case of equality, the first ordering in the list wins\n",
    "            max_freq = 0\n",
    "            most_common = orderings_list[0]\n",
    "            for ordering in orderings_list:\n",
    "                freq = orderings_list.count(list(ordering))\n",
    "                if freq > max_freq:\n",
    "                    max_freq = freq\n",
    "                    most_common = ordering\n",
    "            \n",
    "            self.assemblers[key] = most_common\n",
    "            \n",
    "        \n",
    "    def predict(self, stem: str, i_lemma_group: int, i_morph_attr_group: int):\n",
    "        \n",
    "        assembler = self.assemblers[(i_lemma_group,i_morph_attr_group)]\n",
    "        possible_ngrams = self.ngrams_per_attr_group[i_morph_attr_group]\n",
    "        \n",
    "        prediction = \"\"\n",
    "        \n",
    "        for i in assembler:\n",
    "            if i == -1:\n",
    "                prediction += stem  \n",
    "            else:\n",
    "                prediction += possible_ngrams[i]\n",
    "                \n",
    "        return prediction\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bbb064-af5c-4787-89ed-7ec3ffe71794",
   "metadata": {},
   "source": [
    "#### Unit test with French verb groups\n",
    "This test is designed to make sure that the methods work properly. We will evaluate our performance on multiple languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0498c6f7-a38a-47aa-9d2d-64ef430b0d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_stems = [[(\"mang\",\"mangerai\", 0),(\"mang\",\"mangions\",1),(\"goût\",\"goûterai\",0)],[(\"pun\",\"punirai\",0),(\"fin\",\"finissais\",2)]]\n",
    "ngrams_per_attr_group = [[\"erai\",\"irai\",\"rrai\"],[\"ions\"],[\"issais\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4188e99d-6809-42fd-b926-f6f77c8f0bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = Assembler(grouped_stems,ngrams_per_attr_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b6ace5f7-d2c6-42de-af98-616b759dfff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): [-1, 0], (0, 1): [-1, 0], (1, 0): [-1, 1], (1, 2): [-1, 0]}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler.train()\n",
    "assembler.assemblers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "758a091f-5202-497c-ba5e-f7a587a9a3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trouverai'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler.predict(\"trouv\",0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c0f3a7ea-469e-451a-993a-eea110faef2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gémissais'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler.predict(\"gém\",1,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
